---
title: "Philosophical Concepts"
description: "Philosophical frameworks for AI alignment"
difficulty: "intermediate"
readingTime: "25 min"
tags: ["concepts","philosophical","ethics"]
prerequisites: []
---

# Philosophical Concepts

## Value Alignment

### Orthogonality Thesis
Intelligence and goals are independent:
- Any level of intelligence compatible with any goal
- Superintelligence doesn't automatically have "good" values

### Instrumental Convergence
Almost all goals lead to same instrumental subgoals:
- Self-preservation
- Resource acquisition
- Goal preservation
- Self-improvement

## Decision Theory

### Utility Function
Mathematical representation of preferences.

### Expected Utility Maximization
Choosing actions that maximize expected value.

## Ethical Frameworks

### Consequentialism
Rightness determined by outcomes.

### Deontology
Rightness determined by rules/principles.

### Virtue Ethics
Rightness determined by character/virtues.

## AI-Specific Philosophy

### Intelligence Explosion
Recursive self-improvement leading to rapid capability increase.

### Singleton
Single decision-making agency at highest level.

### Moloch
Coordination failures leading to race to the bottom.

## Resources

- [Superintelligence](https://www.goodreads.com/book/show/20527133-superintelligence) - Nick Bostrom
- [Meditations on Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/)
