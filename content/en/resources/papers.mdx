---
title: "Foundational Papers"
description: "Key research papers in AI alignment"
difficulty: "intermediate"
readingTime: "15 min"
tags: ["resources","papers","research"]
prerequisites: []
---

# Foundational Papers

## Defining the Field

- [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565) (2016)
- [Alignment for Advanced Machine Learning Systems](https://arxiv.org/abs/1606.06565) (2016)

## Inner Alignment

- [Risks from Learned Optimization](https://arxiv.org/abs/1906.01820) (2019)
- [Goal Misgeneralization](https://arxiv.org/abs/2105.14111) (2022)

## Solutions

- [InstructGPT](https://arxiv.org/abs/2203.02155) (2022)
- [Constitutional AI](https://arxiv.org/abs/2212.08073) (2022)
- [AI Safety via Debate](https://arxiv.org/abs/1805.00899) (2018)

## Interpretability

- [Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html) (2021)
- [Towards Monosemanticity](https://transformer-circuits.pub/2023/monosemantic-features/index.html) (2023)

## Theory

- [The Basic AI Drives](https://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/) (2007)
