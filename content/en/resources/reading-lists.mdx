---
title: "Reading Lists by Level"
description: "Curated resources organized by difficulty"
difficulty: "beginner"
readingTime: "10 min"
tags: ["resources","reading-lists","learning"]
prerequisites: []
---

# Reading Lists by Level

## Beginner

### Books
- **The Alignment Problem** - Brian Christian
- **Human Compatible** - Stuart Russell
- **Superintelligence** - Nick Bostrom

### Articles
- [AGI Ruin: A List of Lethalities](https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities)
- [AI Safety Fundamentals](https://aisafetyfundamentals.com/)

## Intermediate

### Papers
- [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)
- [Risks from Learned Optimization](https://arxiv.org/abs/1906.01820)

### Sequences
- [Embedded Agency](https://intelligence.org/2018/10/29/embedded-agency/)
- [Value Learning Sequence](https://www.alignmentforum.org/s/4dHMdK5TLN6xcqtyc)

## Advanced

### Technical Papers
- [InstructGPT](https://arxiv.org/abs/2203.02155)
- [Constitutional AI](https://arxiv.org/abs/2212.08073)
- [Goal Misgeneralization](https://arxiv.org/abs/2105.14111)

## Expert

### Research Agendas
- [MIRI Agent Foundations](https://intelligence.org/files/TechnicalAgenda.pdf)
- [ARC ELK](https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/)
