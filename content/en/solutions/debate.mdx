---
title: "AI Safety via Debate"
description: "Using AI agents debating to surface truth"
difficulty: "advanced"
readingTime: "20 min"
tags: ["debate","scalable-oversight","solutions"]
prerequisites: ["problems/other/scalable-oversight"]
---

# AI Safety via Debate

## Principle (OpenAI/Anthropic)

1. Two AI agents debate a question
2. Human judges who is more convincing
3. Truth should be easier to defend than lies
4. Agents learn to argue truthfully to win

## Example

Question: "Is this plan safe?"
- Agent 1 (honest): Points out flaws
- Agent 2 (deceiver): Claims it's safe
- Judge: Evaluates arguments
- Hopefully: Honesty wins

## Advantages

- Humans don't need to understand full complexity
- Just need to judge arguments
- Scales beyond human capability

## Limitations

1. **Assumes truth is easier to defend**: Not always true
2. **Judge can be fooled**: Persuasion â‰  truth
3. **Collusion**: Agents might cooperate to fool judge
4. **Doesn't solve inner alignment**: Debaters can be deceptive

## Resources

- [AI Safety via Debate](https://arxiv.org/abs/1805.00899) - OpenAI
