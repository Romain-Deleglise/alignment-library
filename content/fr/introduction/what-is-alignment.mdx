---
title: "Qu'est-ce que l'AI Alignment ?"
description: "Comprendre le problème fondamental de l'alignement de l'intelligence artificielle"
difficulty: "beginner"
readingTime: "10 min"
tags: ["fundamentals","introduction","definition"]
prerequisites: []
---

# Qu'est-ce que l'AI Alignment ?

## Définition

L'alignement de l'IA est le problème de créer des systèmes d'intelligence artificielle dont les objectifs et comportements sont alignés avec les valeurs et intentions humaines.

## Le problème fondamental

Créer une IA puissante (AGI - Artificial General Intelligence) qui:
- Fait ce que nous voulons vraiment (pas juste ce que nous spécifions)
- Reste alignée même en devenant plus intelligente
- Ne trouve pas de moyens inattendus de "tricher" sur ses objectifs

## Pourquoi c'est difficile

- Spécifier précisément nos valeurs est presque impossible
- L'IA optimisera ce que nous spécifions, pas ce que nous voulons
- Une IA superintelligente trouvera des solutions que nous n'avons pas anticipées
- Nous n'aurons qu'un seul essai (irreversible après déploiement)

## Ressources

- [AGI Ruin: A List of Lethalities](https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities) - Eliezer Yudkowsky
- [Introduction to AI Safety](https://www.aisafety.com/) - Victoria Krakovna
- [The Alignment Problem](https://brianchristian.org/the-alignment-problem/) - Brian Christian (livre)
