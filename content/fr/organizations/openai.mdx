---
title: "OpenAI Safety Team"
description: "L'équipe de sécurité d'OpenAI"
difficulty: "Beginner"
---

# OpenAI (Safety Team)

## Focus

Alignment scalable, superalignment

## Approche

Pragmatique, itératif

## Recherche clé

- RLHF
- Debate
- Weak-to-strong generalization
- Superalignment (program récent)

## Controverse

Aussi leader capabilities (GPT-4, GPT-5)

## Note

L'équipe Superalignment a été dissoute en 2024 après plusieurs départs de chercheurs clés.

## Ressources

- **Website**: https://openai.com/safety
- [OpenAI Alignment Research](https://openai.com/research)
