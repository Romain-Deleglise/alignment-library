---
title: "Pourquoi c'est urgent ?"
description: "Timeline estimée et urgence du problème de l'alignement"
difficulty: "Beginner"
---

# Pourquoi c'est urgent ?

## Timeline estimée

- Consensus médian chercheurs: AGI probable 2030-2050
- Capabilities accélèrent exponentiellement (GPT-2 → GPT-3 → GPT-4)
- Alignment research: En retard, sous-financé, sous-staffé

## Ratio actuel

- Capabilities funding: ~$200 milliards/an
- Alignment funding: ~$500 millions/an
- **Ratio: 400:1**

## Le problème de la course

- Compétition géopolitique (US vs Chine)
- Compétition corporative (OpenAI, Google, Anthropic, Meta)
- Incentive: Être premier, pas être safe
- Moloch: Course vers le bas

## Ressources

- [AI Timelines](https://www.alignmentforum.org/tag/ai-timelines) - Alignment Forum
- [Racing to the Precipice](https://www.governance.ai/research-paper/racing-to-the-precipice) - GovAI
- [The AI Arms Race](https://futureoflife.org/cause-area/artificial-intelligence/) - Future of Life Institute
